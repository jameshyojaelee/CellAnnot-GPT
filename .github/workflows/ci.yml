name: CI

on:
  push:
    branches: ["main", "develop"]
  pull_request:
  schedule:
    - cron: "0 3 * * *"

jobs:
  build-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        run: pip install poetry

      - name: Install dependencies
        run: |
          poetry config virtualenvs.in-project true
          poetry install --no-interaction \
            --extras "dev" \
            --extras "scanpy" \
            --extras "api" \
            --extras "ui"

      - name: Ruff lint
        run: poetry run ruff check backend frontend evaluation scripts config tests

      - name: Black format check
        run: poetry run black --check backend frontend evaluation scripts config tests

      - name: Mypy type check
        run: poetry run mypy backend

      - name: Run unit tests
        env:
          PYTEST_DISABLE_PLUGIN_AUTOLOAD: "1"
        run: poetry run pytest

      - name: Scanpy CLI smoke test (offline)
        run: |
          tmp_dir=$(mktemp -d)
          poetry run python <<PY
            from pathlib import Path
            import numpy as np
            import pandas as pd
            import scanpy as sc

            tmp = Path("${tmp_dir}")
            matrix = np.zeros((6, 4), dtype=float)
            matrix[:3, 0] = 5
            matrix[3:, 1] = 5
            obs = pd.DataFrame({'cluster': ['0', '0', '0', '1', '1', '1']})
            var = pd.DataFrame(index=['MS4A1', 'CD3E', 'GNLY', 'LYZ'])
            adata = sc.AnnData(matrix, obs=obs, var=var)
            sc.pp.normalize_total(adata)
            sc.pp.log1p(adata)
            sc.tl.rank_genes_groups(adata, groupby='cluster', n_genes=3)
            adata.write_h5ad(tmp / 'smoke.h5ad')
PY
          poetry run gca scanpy annotate "$tmp_dir/smoke.h5ad" \
            --cluster-key cluster \
            --species "Homo sapiens" \
            --batch-size 2 \
            --concurrency 1 \
            --summary-json "$tmp_dir/smoke_report.json" \
            --stats-json "$tmp_dir/smoke_stats.json" \
            --offline
          test -s "$tmp_dir/smoke_report.json"
          rm -rf "$tmp_dir"

      - name: Build distribution artifacts
        run: |
          poetry build
          ls dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-${{ github.sha }}
          path: dist

      - name: Build Docker image
        run: docker build -t gpt-cell-annotator-ci .

      - name: Log in to GHCR
        if: github.ref == 'refs/heads/main'
        env:
          GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
        run: |
          if [ -z "$GHCR_TOKEN" ]; then
            echo "GHCR_TOKEN not set; skipping login"
            exit 0
          fi
          echo "$GHCR_TOKEN" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      - name: Tag and push image
        if: github.ref == 'refs/heads/main'
        env:
          GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
        run: |
          if [ -z "$GHCR_TOKEN" ]; then
            echo "GHCR_TOKEN not set; skipping push"
            exit 0
          fi
          IMAGE=ghcr.io/${{ github.repository }}/gpt-cell-annotator:${{ github.sha }}
          docker tag gpt-cell-annotator-ci "$IMAGE"
          docker push "$IMAGE"

      - name: Run Trivy scan
        uses: aquasecurity/trivy-action@0.13.0
        with:
          image-ref: gpt-cell-annotator-ci
          format: 'table'
          exit-code: '1'
          ignore-unfixed: true
          vuln-type: 'os,library'

  benchmarks:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        run: pip install poetry

      - name: Install deps
        run: |
          poetry config virtualenvs.in-project true
          poetry install --no-interaction \
            --extras "dev" \
            --extras "scanpy" \
            --extras "api" \
            --extras "ui"

      - name: Run benchmarks (mock)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ALLOW_BENCHMARK_REGRESSIONS: ${{ env.ALLOW_BENCHMARK_REGRESSIONS }}
        run: |
          poetry run python scripts/run_benchmarks.py --mock --output-dir docs/reports

      - name: Upload reports
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-reports
          path: docs/reports

      - name: Upload benchmark diff summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-diff-summary
          path: |
            docs/reports/latest/diff_summary.json
            docs/reports/latest/*.csv
